# Story 1.3: Agent Router

> **Epic:** 1 - API Foundation & Agent Router
> **Sprint:** S2 (Week 2)
> **Priority:** P0 (core NL→agent mapping)
> **Points:** 8
> **Type:** Backend/AI
> **Agent:** @dev
> **Depends on:** Story 1.1 (FastAPI Server), Story 1.2 (WebSocket), Story 3.1 (AI Engine/LiteLLM)

---

## Status

**Done**

---

## Story

**As a** user,
**I want** my natural language commands automatically routed to the correct agent,
**so that** I don't need to manually select which agent to use.

---

## Acceptance Criteria

1. Agent Router receives NL text and returns the target agent + extracted parameters
2. Router correctly classifies commands into: network-analyst, meraki-specialist, workflow-creator
3. Classification accuracy > 90% on a test set of 50 common commands
4. Router provides confidence score (0-1) for each classification
5. Commands with confidence < 0.7 prompt user to confirm agent selection
6. Router supports explicit agent selection via prefix: `@analyst analyze my network`
7. Router maintains conversation context for multi-turn interactions

---

## Integration Verification

- **IV1:** All existing agent capabilities (discovery, config, workflow) are routable
- **IV2:** Router does not modify the agent definitions — it reads them as-is
- **IV3:** Fallback to manual agent selection works when router is uncertain

---

## Dependencies

| Direction | Story | Title | Status |
|-----------|-------|-------|--------|
| Blocked by | 1.1 | FastAPI Server Bootstrap | Draft |
| Blocked by | 3.1 | LiteLLM AI Engine | Draft |
| Blocks | 1.2 | WebSocket Chat Endpoint | Draft |
| Blocks | 3.2 | Agent Prompts | Draft |

---

## CodeRabbit Integration

> **CodeRabbit Integration**: Enabled
> **Profile**: assertive
> **Quality Gates**: block_on_critical=true, require_resolution=true

### Applicable Path Instructions

**`scripts/**/*.py`** (agent_router.py, server.py integration):
- CRITICAL: No hardcoded API keys — must use `~/.meraki/credentials` or env vars
- CRITICAL: No command injection via user NL input passed to agents
- CRITICAL: Meraki API rate limit compliance (10 req/s per org) in function execution
- CRITICAL: No sensitive network data exposed in classification logs
- HIGH: Error handling for Meraki API calls in `FUNCTION_REGISTRY` execution (timeouts, 429)
- HIGH: Type hints on all public functions (`classify_intent`, `process_message`, etc.)
- HIGH: No blocking calls in async context — use `asyncio.to_thread()` for sync modules
- MEDIUM: Functions under 50 lines (watch `process_message` complexity)

**`tests/**/*.py`** (test_agent_router.py):
- VALIDATE: Meraki API calls properly mocked (never hit real API)
- VALIDATE: Edge cases covered (empty input, unknown language, malformed prefix)
- VALIDATE: Test names descriptive
- DO NOT: Require docstrings in test functions

### Review Focus for This Story
- Agent router must sanitize NL input before passing to regex patterns (ReDoS prevention)
- LLM classify fallback chain must not leak API keys in error messages
- `FUNCTION_REGISTRY` execution via `asyncio.to_thread()` must handle exceptions from existing modules
- Confidence threshold logic (< 0.7 → confirm) must be tested at boundary values

---

## Tasks / Subtasks

- [x] **T1: Create `scripts/agent_router.py` — Agent definitions and registry** (AC: 1, 2)
  - [x] T1.1: Define `AgentDefinition` dataclass: name, description, system_prompt, functions, icon, examples
  - [x] T1.2: Define `ClassificationResult` dataclass: agent_name, confidence, reasoning, requires_confirmation
  - [x] T1.3: Create `AGENTS` dict with 3 agent definitions (network-analyst, meraki-specialist, workflow-creator)
  - [x] T1.4: Load agent system prompts from `.claude/agents/*.md` files
  - [x] T1.5: Create `FUNCTION_REGISTRY` mapping function names to actual Python callables from existing modules

- [x] **T2: Implement quick (rule-based) classifier** (AC: 2, 6)
  - [x] T2.1: Implement `_quick_classify(message: str) -> Optional[ClassificationResult]`
  - [x] T2.2: Regex patterns: `discover|scan|analyz|diagnos|health|status|offline|inventory` → network-analyst
  - [x] T2.3: Regex patterns: `config|ssid|vlan|firewall|acl|switch|port|camera|block|allow|deny` → meraki-specialist
  - [x] T2.4: Regex patterns: `workflow|automat|schedule|alert|notif|trigger|template` → workflow-creator
  - [x] T2.5: Handle explicit prefix: `@analyst`, `@specialist`, `@workflow` → direct routing with confidence 1.0
  - [x] T2.6: Return None if no pattern matches (fall through to LLM)

- [x] **T3: Implement LLM-based classifier** (AC: 1, 3, 4)
  - [x] T3.1: Implement `async _llm_classify(message: str) -> ClassificationResult`
  - [x] T3.2: Use AI Engine (Story 3.1) function-calling with `route_to_agent` tool definition
  - [x] T3.3: Tool schema: `{agent: enum[agents], confidence: float, reasoning: str}`
  - [x] T3.4: Parse LLM response into ClassificationResult
  - [x] T3.5: Handle LLM unavailable → fall back to quick_classify with lower confidence

- [x] **T4: Implement classification pipeline** (AC: 1, 4, 5)
  - [x] T4.1: Implement `async classify_intent(message: str) -> ClassificationResult`
  - [x] T4.2: Pipeline: explicit prefix check → quick_classify (if confidence > 0.9) → llm_classify
  - [x] T4.3: If final confidence < 0.7 → set `requires_confirmation = True`
  - [x] T4.4: Log classification result with agent, confidence, method used

- [x] **T5: Implement agent execution pipeline** (AC: 1, 7)
  - [x] T5.1: Implement `async process_message(message: str, session: ChatSession) -> AsyncGenerator[dict, None]`
  - [x] T5.2: Classify intent → select agent → build prompt with context
  - [x] T5.3: If `requires_confirmation` → yield confirm message and await response
  - [x] T5.4: Build system prompt: agent definition + network context (org name, network count)
  - [x] T5.5: Include last 20 messages from session for multi-turn context
  - [x] T5.6: Send to AI Engine with function-calling enabled (agent's functions as tools)
  - [x] T5.7: Execute returned function calls against `FUNCTION_REGISTRY` via `asyncio.to_thread()`
  - [x] T5.8: Yield streaming chunks: `{type: "stream", chunk: "...", agent: "..."}`
  - [x] T5.9: Yield structured data: `{type: "data", format: "...", data: {...}, agent: "..."}`

- [x] **T6: Implement function call execution** (AC: 1)
  - [x] T6.1: Parse LLM tool_calls response → extract function name + arguments
  - [x] T6.2: Look up function in `FUNCTION_REGISTRY`
  - [x] T6.3: Execute via `await asyncio.to_thread(func, **args)`
  - [x] T6.4: Handle exceptions from existing modules gracefully
  - [x] T6.5: Return function results to LLM for response generation

- [ ] **T7: Connect router to WebSocket handler** (AC: all) — **DEFERRED to Story 1.2**
  - [ ] T7.1: In `scripts/server.py`, replace WebSocket stub with `agent_router.process_message()`
  - [ ] T7.2: Wire `async for chunk in router.process_message(...)` → `websocket.send_json(chunk)`
  - [ ] T7.3: Handle confirmation flow between WebSocket and router

- [x] **T8: Create test set and verify accuracy** (AC: 3)
  - [x] T8.1: Create `tests/test_classification_set.json` with 50 common commands + expected agent
  - [x] T8.2: Test quick_classify accuracy on the set
  - [x] T8.3: Test full pipeline accuracy (mock LLM to return expected results)
  - [x] T8.4: Verify > 90% accuracy on test set (achieved 96% accuracy)

- [x] **T9: Write unit tests**
  - [x] T9.1: `tests/test_agent_router.py` — Test AgentDefinition and ClassificationResult
  - [x] T9.2: Test quick_classify for each agent pattern
  - [x] T9.3: Test explicit prefix routing (`@analyst`, `@specialist`, `@workflow`)
  - [x] T9.4: Test LLM classify with mocked AI Engine
  - [x] T9.5: Test pipeline priority (prefix > quick > llm)
  - [x] T9.6: Test low confidence → requires_confirmation
  - [x] T9.7: Test function registry execution
  - [x] T9.8: Ensure all tests pass: `pytest tests/test_agent_router.py -v` (31/31 passed)

---

## Dev Notes

### Agent Router Architecture

[Source: architecture.md#5.2 Agent Router]

```python
# scripts/agent_router.py

AGENTS = {
    "network-analyst": AgentDefinition(
        name="network-analyst",
        description="Network discovery, analysis, diagnostics",
        functions=["full_discovery", "discover_networks", "discover_devices",
                   "discover_ssids", "find_issues", "generate_suggestions",
                   "compare_snapshots", "save_snapshot"],
        system_prompt="...",  # Loaded from .claude/agents/network-analyst.md
    ),
    "meraki-specialist": AgentDefinition(
        name="meraki-specialist",
        description="Configure ACL, Firewall, SSID, VLAN, Switch, Camera",
        functions=["configure_ssid", "enable_ssid", "disable_ssid",
                   "add_firewall_rule", "remove_firewall_rule",
                   "add_switch_acl", "create_vlan", "update_vlan",
                   "backup_config", "rollback_config"],
        system_prompt="...",
    ),
    "workflow-creator": AgentDefinition(
        name="workflow-creator",
        description="Create automation workflows in Cisco/SecureX format",
        functions=["create_device_offline_handler", "create_firmware_compliance_check",
                   "create_scheduled_report", "create_security_alert_handler",
                   "create_workflow_from_template", "list_workflows"],
        system_prompt="...",
    ),
}
```

### Function Registry

[Source: architecture.md#5.2 Agent Router - Function Registry]

```python
FUNCTION_REGISTRY = {
    # discovery.py
    "full_discovery": scripts.discovery.full_discovery,
    "discover_networks": scripts.discovery.discover_networks,
    "find_issues": scripts.discovery.find_issues,
    "save_snapshot": scripts.discovery.save_snapshot,
    "compare_snapshots": scripts.discovery.compare_snapshots,
    # config.py
    "configure_ssid": scripts.config.configure_ssid,
    "add_firewall_rule": scripts.config.add_firewall_rule,
    "add_switch_acl": scripts.config.add_switch_acl,
    "backup_config": scripts.config.backup_config,
    "rollback_config": scripts.config.rollback_config,
    # workflow.py
    "create_device_offline_handler": scripts.workflow.create_device_offline_handler,
    "save_workflow": scripts.workflow.save_workflow,
    # report.py
    "generate_discovery_report": scripts.report.generate_discovery_report,
}
```

### Classification via LLM Function-Calling

[Source: architecture.md#5.3 AI Engine - classify method]

```python
tools = [{
    "type": "function",
    "function": {
        "name": "route_to_agent",
        "description": "Route the user's message to the appropriate agent",
        "parameters": {
            "type": "object",
            "properties": {
                "agent": {
                    "type": "string",
                    "enum": ["network-analyst", "meraki-specialist", "workflow-creator"],
                },
                "confidence": {"type": "number"},
                "reasoning": {"type": "string"}
            },
            "required": ["agent", "confidence"]
        }
    }
}]
```

### Decision Record

[Source: architecture.md#3.3 DR2 - Agent Router]

**Decision:** LLM function-calling for intent classification, with regex/keyword fallback when LLM is unavailable.

**Rationale:** LLM provides natural, flexible classification. Fallback rules handle obvious commands. Confidence scoring allows "I'm not sure" responses.

### Existing Agent Definitions (DO NOT MODIFY)

[Source: .claude/agents/*.md]

- `.claude/agents/network-analyst.md` — Discovery, analysis, diagnostics persona
- `.claude/agents/meraki-specialist.md` — Configuration specialist persona
- `.claude/agents/workflow-creator.md` — Workflow automation persona

Load these as system prompts: `Path(".claude/agents/{name}.md").read_text()`

### File Locations

| File | Location | Purpose |
|------|----------|---------|
| Agent Router | `scripts/agent_router.py` | Intent classification + dispatch |
| Classification test set | `tests/test_classification_set.json` | 50 command → agent pairs |
| Unit tests | `tests/test_agent_router.py` | Router tests |
| Server integration | `scripts/server.py` | Wire router to WebSocket |

---

## Testing

- **Framework:** pytest
- **Location:** `tests/test_agent_router.py`
- **Coverage target:** 90%
- **Classification accuracy:** > 90% on 50-command test set

```python
import pytest
from scripts.agent_router import AgentRouter, ClassificationResult

def test_quick_classify_discovery():
    router = AgentRouter(ai_engine=None)
    result = router._quick_classify("discover all networks")
    assert result.agent_name == "network-analyst"
    assert result.confidence > 0.8

def test_quick_classify_config():
    router = AgentRouter(ai_engine=None)
    result = router._quick_classify("add firewall rule to block port 23")
    assert result.agent_name == "meraki-specialist"

def test_explicit_prefix():
    router = AgentRouter(ai_engine=None)
    result = router._quick_classify("@analyst check network health")
    assert result.agent_name == "network-analyst"
    assert result.confidence == 1.0

def test_low_confidence_needs_confirmation():
    result = ClassificationResult(
        agent_name="network-analyst", confidence=0.5, reasoning="unclear"
    )
    # confidence < 0.7 should require confirmation
```

Run tests: `pytest tests/test_agent_router.py -v`

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-02-05 | 0.1.0 | Story created from PRD + Architecture | River (SM) |
| 2026-02-05 | 0.1.1 | CodeRabbit integration enabled — assertive profile, path instructions + review focus added | River (SM) |
| 2026-02-05 | 0.1.2 | Added structured Dependencies section per PO validation | River (SM) |

---

## Dev Agent Record

### Agent Model Used
- Claude Sonnet 4.5 (claude-sonnet-4-5-20250929)

### Debug Log References
- Test output: `pytest tests/test_agent_router.py -v` (31/31 passed)
- Classification accuracy: 96% (48/50 on test set)

### Completion Notes List
1. **Pattern Matching Enhancement**: Used regex with wildcards (`\w*`) to match word variations (e.g., `analyz\w*` matches "analyze", "analyzing", "analysis")
2. **Weighted Scoring**: Applied agent-specific weights (workflow-creator: 1.5x, meraki-specialist: 1.2x) to prioritize more specific keywords
3. **ReDoS Prevention**: Implemented `_sanitize_input()` to truncate long inputs and remove control characters
4. **Graceful Degradation**: LLM classifier falls back to quick classifier if AI engine unavailable
5. **T7 Deferred**: WebSocket integration deferred to Story 1.2 as it depends on the WebSocket server implementation

### File List
1. **Created**: `/Users/josdasil/Documents/Meraki_Workflow/scripts/agent_router.py` (~550 lines)
   - `AgentDefinition` and `ClassificationResult` dataclasses
   - `AGENTS` registry (3 agents: network-analyst, meraki-specialist, workflow-creator)
   - `FUNCTION_REGISTRY` (20+ functions from discovery, config, workflow, report modules)
   - `_quick_classify()` - Rule-based classification with regex patterns
   - `_llm_classify()` - LLM-based classification via AIEngine
   - `classify_intent()` - Pipeline with explicit prefix → quick → LLM fallback
   - `_execute_function()` - Async function execution via asyncio.to_thread()
   - `process_message()` - Full agent execution pipeline with streaming

2. **Created**: `/Users/josdasil/Documents/Meraki_Workflow/tests/test_classification_set.json` (50 test commands)
   - 12 network-analyst commands
   - 17 meraki-specialist commands
   - 11 workflow-creator commands
   - 10 question-based commands

3. **Created**: `/Users/josdasil/Documents/Meraki_Workflow/tests/test_agent_router.py` (~510 lines, 31 tests)
   - Data class tests (2)
   - Registry tests (2)
   - Sanitization tests (1)
   - Quick classification tests (8)
   - LLM classification tests (2)
   - Pipeline tests (4)
   - Function execution tests (3)
   - Message processing tests (3)
   - Accuracy test on full test set (1)
   - Edge case tests (5)

4. **Updated**: `/Users/josdasil/Documents/Meraki_Workflow/docs/stories/1.3.story.md`
   - Status: Draft → Done
   - All tasks marked complete except T7 (deferred)
   - Dev Agent Record filled

---

## QA Results
_(To be filled by QA agent)_
