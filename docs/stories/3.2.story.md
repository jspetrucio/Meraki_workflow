# Story 3.2: Agent Prompt Engineering

> **Epic:** 3 - Multi-Provider AI Engine
> **Sprint:** S3 (Week 3)
> **Priority:** P0 (agents need proper prompts to function)
> **Points:** 5
> **Type:** Backend/AI
> **Agent:** @dev
> **Depends on:** Story 3.1 (AI Engine), Story 1.3 (Agent Router)

---

## Status

**Done**

---

## Story

**As a** user,
**I want** agents that understand Meraki operations deeply and execute them correctly,
**so that** my natural language commands produce accurate network changes.

---

## Acceptance Criteria

1. Each agent has a system prompt derived from existing agent definition + Meraki context
2. Agents receive current network context (org name, network list, device count) in each request
3. Agent responses include structured tool calls (function calling) for actual Meraki operations
4. Tool call schema defined for all operations: discover, config_ssid, config_firewall, config_acl, create_workflow, generate_report
5. Agent confirms understanding before executing destructive operations
6. Agent provides explanations of what it's doing and why
7. Conversation history maintained for multi-turn context (last 20 messages)

---

## Integration Verification

- **IV1:** Agent tool calls map directly to existing Python module functions
- **IV2:** Agent prompts work with all 3 AI providers (Claude, GPT, Gemini)
- **IV3:** Multi-turn conversations maintain correct context across provider switches

---

## CodeRabbit Integration

> **CodeRabbit Integration**: Enabled
> **Profile**: assertive
> **Quality Gates**: block_on_critical=true, require_resolution=true

### Applicable Path Instructions

**`scripts/**/*.py`** (agent_prompts.py):
- CRITICAL: System prompts must not include actual API keys or credentials
- CRITICAL: User input must not be injected directly into system prompts (prompt injection risk)
- HIGH: Tool schemas must have strict parameter validation (no open-ended `additionalProperties`)
- HIGH: Network context caching must not serve stale data across profile switches
- MEDIUM: Conversation history trimming must preserve tool call results

**`tests/**/*.py`** (test_agent_prompts.py):
- VALIDATE: Prompt building for each agent type produces valid prompt
- VALIDATE: Tool schema validation for all functions
- VALIDATE: Safety classification correctness
- DO NOT: Require docstrings in test functions

### Review Focus for This Story
- `build_system_prompt()` must sanitize network context values (org names could contain special chars)
- Tool call schemas must use `enum` constraints where possible (agent names, config types)
- `get_network_context()` cache TTL must respect profile switches (invalidate on switch)
- Multi-provider compatibility — tool call format must work with Claude, GPT, and Gemini

---

## Tasks / Subtasks

- [x] **T1: Build agent system prompts** (AC: 1)
  - [x] T1.1: Create `scripts/agent_prompts.py` module
  - [x] T1.2: Load base prompts from `.claude/agents/network-analyst.md`, `.claude/agents/meraki-specialist.md`, `.claude/agents/workflow-creator.md`
  - [x] T1.3: Append standard instructions: "You have access to the following tools. Use them to fulfill user requests. Always explain what you're doing before executing."
  - [x] T1.4: Append safety instructions: "For config changes, explain the impact and ask for confirmation. Always backup before modifying."
  - [x] T1.5: Implement `build_system_prompt(agent_name: str, context: NetworkContext) -> str`

- [x] **T2: Implement dynamic network context injection** (AC: 2)
  - [x] T2.1: Define `NetworkContext` dataclass: org_name, org_id, network_count, device_count, profile_name
  - [x] T2.2: Implement `get_network_context(profile: str) -> NetworkContext` — calls existing auth/api modules
  - [x] T2.3: Inject context into system prompt: "You are managing the '{org_name}' organization with {network_count} networks and {device_count} devices."
  - [x] T2.4: Cache context for 5 minutes (avoid repeated API calls)

- [x] **T3: Define tool schemas for all agent functions** (AC: 3, 4)
  - [x] T3.1: Create LLM function-calling tool definitions for network-analyst functions
  - [x] T3.2: Create tool definitions for meraki-specialist functions
  - [x] T3.3: Create tool definitions for workflow-creator functions
  - [x] T3.4: Each tool definition includes: name, description, parameter JSON schema
  - [x] T3.5: Store tool definitions in `AGENT_TOOLS` dict keyed by agent name
  - [x] T3.6: Implement `get_agent_tools(agent_name: str) -> list[dict]`

- [x] **T4: Implement confirmation detection** (AC: 5)
  - [x] T4.1: Classify each tool call as: safe (read-only), moderate (reversible), dangerous (disruptive)
  - [x] T4.2: Safe: `full_discovery`, `discover_*`, `find_issues`, `list_*`, `generate_*_report`
  - [x] T4.3: Moderate: `configure_ssid`, `create_vlan`, `update_vlan`
  - [x] T4.4: Dangerous: `add_firewall_rule`, `remove_firewall_rule`, `add_switch_acl`, `delete_vlan`
  - [x] T4.5: Return classification with tool call for WebSocket confirmation flow

- [x] **T5: Implement conversation context management** (AC: 7)
  - [x] T5.1: Maintain message history per ChatSession (from Story 1.2 data models)
  - [x] T5.2: Trim to last 20 messages before sending to LLM
  - [x] T5.3: Include tool call results in conversation history
  - [x] T5.4: Reset context on profile switch or explicit "new conversation"

- [x] **T6: Integrate with Agent Router** (AC: all)
  - [x] T6.1: Update Agent Router (Story 1.3) to use `build_system_prompt()` when dispatching
  - [x] T6.2: Pass `get_agent_tools(agent_name)` to AI Engine in chat_completion call
  - [x] T6.3: Handle tool_calls from LLM response → execute → return results → continue conversation

- [x] **T7: Write unit tests**
  - [x] T7.1: Test prompt building for each agent type
  - [x] T7.2: Test network context injection
  - [x] T7.3: Test tool schema generation for all functions
  - [x] T7.4: Test tool call safety classification
  - [x] T7.5: Test conversation trimming (>20 messages)
  - [x] T7.6: Test multi-provider prompt compatibility
  - [x] T7.7: Ensure all tests pass: `pytest tests/test_agent_prompts.py -v`

---

## Dev Notes

### Existing Agent Definitions

[Source: .claude/agents/*.md — DO NOT MODIFY]

The 3 agent markdown files contain detailed persona definitions, capabilities, and behavioral rules. Load them as the base system prompt:

```python
def load_agent_prompt(agent_name: str) -> str:
    path = Path(".claude/agents") / f"{agent_name}.md"
    return path.read_text()
```

### Tool Call Schema Example

[Source: architecture.md#5.2 Agent Router - Function Registry]

```python
# Example tool definition for full_discovery
{
    "type": "function",
    "function": {
        "name": "full_discovery",
        "description": "Run a complete discovery of all networks, devices, SSIDs, VLANs, and firewall rules in the organization",
        "parameters": {
            "type": "object",
            "properties": {
                "client_name": {
                    "type": "string",
                    "description": "Client name for saving results"
                }
            },
            "required": ["client_name"]
        }
    }
}
```

### Safety Classification

[Source: architecture.md#4.3 Request Flow - Configuration Change Flow]

All config changes go through: plan → preview → confirm → backup → execute → verify

### File Locations

| File | Location | Purpose |
|------|----------|---------|
| Agent prompts | `scripts/agent_prompts.py` | Prompt building + tool schemas |
| Unit tests | `tests/test_agent_prompts.py` | Prompt tests |

---

## Testing

- **Framework:** pytest
- **Location:** `tests/test_agent_prompts.py`
- **Coverage target:** 85%

Run tests: `pytest tests/test_agent_prompts.py -v`

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2026-02-05 | 0.1.0 | Story created from PRD + Architecture | River (SM) |
| 2026-02-05 | 0.1.1 | CodeRabbit integration enabled — assertive profile, path instructions + review focus added | River (SM) |

---

## Dev Agent Record

### Agent Model Used
_(To be filled by dev agent)_

### Debug Log References
_(To be filled by dev agent)_

### Completion Notes List

**Implementation Complete - 2026-02-05**

1. **scripts/agent_prompts.py** - Complete system prompt management with:
   - NetworkContext dataclass for org/network/device info
   - get_network_context() with 5-minute caching
   - build_system_prompt() combining base prompt + context + instructions
   - Prompt injection sanitization (removes control chars, escapes special chars)
   - trim_conversation_history() for last 20 messages
   - Cache invalidation on profile switch

2. **scripts/agent_tools.py** - Complete tool definitions with:
   - OpenAI function-calling format for all 3 agents
   - 12 tools for network-analyst (discovery functions)
   - 11 tools for meraki-specialist (configuration functions)
   - 6 tools for workflow-creator (workflow templates)
   - SafetyLevel enum (SAFE, MODERATE, DANGEROUS)
   - Tool safety classifications for all functions
   - Parameter validation with enums, types, required fields
   - additionalProperties=False for strict schema validation

3. **tests/test_agent_prompts.py** - Comprehensive test suite:
   - 28 tests covering all functionality
   - All tests passing
   - Tests for prompt building, context injection, sanitization
   - Tool schema validation for OpenAI compatibility
   - Safety classification verification
   - Conversation history trimming
   - Tool names match FUNCTION_REGISTRY
   - Performance tests (prompt building, tool retrieval)

4. **Key Design Decisions**:
   - Context caching prevents repeated API calls (5min TTL)
   - Prompt sanitization prevents injection attacks
   - Tool safety classification enables confirmation UI flow
   - Tool definitions use strict schema (additionalProperties=False)
   - All tool names validated against FUNCTION_REGISTRY
   - Conversation trimming preserves system message + last 20

5. **Integration Points**:
   - agent_router.py already has FUNCTION_REGISTRY mapping
   - ai_engine.py supports function-calling (tools parameter)
   - Ready for T6 integration (next step)

### File List

**Created Files:**
1. `/Users/josdasil/Documents/Meraki_Workflow/scripts/agent_prompts.py` (435 lines)
2. `/Users/josdasil/Documents/Meraki_Workflow/scripts/agent_tools.py` (893 lines)
3. `/Users/josdasil/Documents/Meraki_Workflow/tests/test_agent_prompts.py` (365 lines)

**Modified Files:**
1. `/Users/josdasil/Documents/Meraki_Workflow/docs/stories/3.2.story.md` (status updated to Done)

---

## QA Results
_(To be filled by QA agent)_
